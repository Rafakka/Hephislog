
<div align="center"><img width="424" height="424" alt="Hephislog_icon" src="https://github.com/user-attachments/assets/69655ad8-ee6a-44d2-9657-15db7d7d60d1" /></div>

ENG

## Hephislog¬∫ - Event-Driven Swarm Pipeline for Inteligent Data Ingestion & Normalization

  The system is built as a swarm of single-resposability agents, coordinated via and internal event bus, enabling flexible orchestration, traceability, and continuos learning across runs.

  This project demonstrates production-grade patterns commonly required in IT consulting, system integration, data plataforms, and observability-heavy enviroments.

  Hephislog¬∫ is a modular, event driven processing framework designed to ingest unstructured inputs, infer intent through probabilistic signals, and transform them into validated, normalized, and auditable outputs, without hard coded pipelines.

---

## Core Concepts

### Event-Driven Architecture

All processing is coordinated through a decoupled event bus. 
Agents subscribe to semantic events (e.g. system.input_received, intent.organize.music) rather than calling each other directly.

### Swarm-Based Agent Design

Each agent performs one well-defined role:

- sniffing & signal extraction
- input identification
- decision-making under uncertainty
- domain organization
- normalization & validation
- packing & persistence
- reporting & diagnostics

### Probabilistic Decision Layer

Instead of rigid routing rules, inputs are evaluated using confidence-weighted ‚Äúsmells‚Äù, allowing the system to:

- decline low-confidence flows safely
- adapt to ambiguous or noisy data
- learn from previous outcomes over time

### Full Observability & Audit Trail

Every run produces a structured execution context:

- facts emitted per stage
- agent actions and decisions
- final reports with diagnostics
- reproducible run IDs for tracing

### üîÑ High-Level Flow

- Input arrives (file, text, URL, API payload)
- Sniffer agents extract weak signals (‚Äúsmells‚Äù) from raw data
- Identifier & Extractor agents detect format and domain
- Decision agent selects the best domain using confidence thresholds
- Organizer & Normalizer agents structure and validate content
- Universal packer serializes output into domain-ready artifacts
- Finalizer & Reporter agents persist results and generate diagnostics

The pipeline is self-orchestrating ‚Äî adding a new domain requires no central rewrite.

### üß© Designed for Extension

Plug-in friendly (new agents auto-register via decorators)
Domain-agnostic core (music, recipes, APIs, documents, etc.)

Clear separation between:

- detection
- decision
- transformation
- persistence

Safe failure paths (decline instead of corrupting data)

This makes Hephislog¬∞ suitable as:

- a data ingestion backbone
- a legacy-system integration layer
- a pre-normalization gateway
- a teaching example of clean event-driven design

### üß™ Engineering Practices Demonstrated

- Deterministic pipelines with probabilistic reasoning
- Idempotent runs with execution context isolation
- Structured logging and reporting
- Testable flows (integration tests simulate full pipelines)
- Zero tight coupling between agents

PT-BR

## Hephislog¬∫ - Pipeline de Enxame Orientado a Eventos para Ingest√£o e Normaliza√ß√£o Inteligente de Dados

  O sistema √© constru√≠do como um SWARM de agentes com responsabilidade √∫nica, coordenados por meio de um BUS de eventos interno, permitindo orquestra√ß√£o flex√≠vel, rastreabilidade e aprendizado cont√≠nuo entre execu√ß√µes.

  Este projeto demonstra padr√µes de n√≠vel de produ√ß√£o comumente exigidos em consultoria de TI, integra√ß√£o de sistemas, plataformas de dados e ambientes com alta observabilidade.

  O Hephislog¬∫ √© uma estrutura de processamento modular, orientada a eventos, projetada para ingerir entradas n√£o estruturadas, inferir inten√ß√µes por meio de sinais probabil√≠sticos e transform√°-las em sa√≠das validadas, normalizadas e audit√°veis, sem a necessidade de pipelines predefinidos.

  ---

## Conceitos Essenciais

### Arquitetura Orientada a Eventos

Todo o processamento √© coordenado por meio de um barramento de eventos desacoplado. 
Os agentes se inscrevem em eventos sem√¢nticos (por exemplo, system.input_received, intent.organize.music) em vez de se comunicarem diretamente.

### Projeto de Agentes Baseado em Enxame

Cada agente desempenha uma fun√ß√£o bem definida:

- Captura e extra√ß√£o de sinais
- Identifica√ß√£o de entrada
- Tomada de decis√£o sob incerteza
- Organiza√ß√£o do dom√≠nio
- Normaliza√ß√£o e valida√ß√£o
- Empacotamento e persist√™ncia
- Relat√≥rios e diagn√≥sticos

### Camada de Decis√£o Probabil√≠stica

Em vez de regras de roteamento r√≠gidas, as entradas s√£o avaliadas usando "cheiros" ponderados por confian√ßa, permitindo que o sistema:

- rejeite fluxos de baixa confian√ßa com seguran√ßa
- se adapte a dados amb√≠guos ou ruidosos
- aprenda com resultados anteriores ao longo do tempo

### Observabilidade Completa e Rastreamento de Auditoria

Cada execu√ß√£o produz um contexto de execu√ß√£o estruturado:

- fatos emitidos por est√°gio
- a√ß√µes e decis√µes dos agentes
- relat√≥rios finais com diagn√≥sticos
- IDs de execu√ß√£o reproduz√≠veis para rastreamento

### üîÑ Fluxo de Alto N√≠vel

- Entrada chega (arquivo, texto, URL, payload da API)
- Agentes de captura extraem sinais fracos ("cheiros") dos dados brutos
- Os agentes Identificador e Extrator detectam o formato e o dom√≠nio.
- O agente de Decis√£o seleciona o melhor dom√≠nio usando limites de confian√ßa.
- Os agentes Organizador e Normalizador estruturam e validam o conte√∫do.
- O empacotador universal serializa a sa√≠da em artefatos prontos para o dom√≠nio.
- Os agentes Finalizador e Relator persistem os resultados e geram diagn√≥sticos.

O pipeline √© auto-orquestrado ‚Äî adicionar um novo dom√≠nio n√£o requer nenhuma reescrita central.

### üß© Projetado para Extens√µes

Amig√°vel a plug-ins (novos agentes se registram automaticamente via decoradores)

N√∫cleo agn√≥stico a dom√≠nios (m√∫sica, receitas, APIs, documentos, etc.)

Separa√ß√£o clara entre:

- detec√ß√£o
- decis√£o
- transforma√ß√£o
- persist√™ncia

Caminhos seguros para falhas (descartar em vez de corromper os dados)

Isso torna o Hephislog¬∞ adequado como:

- uma infraestrutura de ingest√£o de dados
- uma camada de integra√ß√£o com sistemas legados
- um gateway de pr√©-normaliza√ß√£o
- um exemplo did√°tico de design orientado a eventos limpo

### üß™ Pr√°ticas de Engenharia Demonstradas

- Pipelines determin√≠sticos com racioc√≠nio probabil√≠stico
- Execu√ß√µes idempotentes com isolamento do contexto de execu√ß√£o
- Registro e gera√ß√£o de relat√≥rios estruturados
- Fluxos test√°veis ‚Äã‚Äã(testes de integra√ß√£o simulam pipelines completos)
- Acoplamento zero entre agentes

  ---
